\documentclass[11pt]{article}


\usepackage{url}
\usepackage{html}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{cite}
\usepackage[margin=1in]{geometry}

\begin{document}

\title{Generating Empirically Optimized Numerical Software from Matlab Prototypes}

\abstract{}

\section{Introduction}
\label{sec:intro}

%Words here in Intro and Back are lifted from a 2004 proposal by Liz, Bill, and Jack, written almost completely by Liz.   Perhaps dated but
% at least a jumping off point.

The growing demand for higher levels of detail and accuracy in results means that the size and complexity of scientific computations is increasing at least as fast as the improvements in processor technology. Programming scientific applications is hard, and optimizing them for high performance is even harder.  The development of optimized codes requires extensive knowledge, not only of the costs of floating-point arithmetic but also of  memory access issues and of the compiler being used. Hardware platforms are continually evolving. In addition, experiments show that the complexity of this  hardware-software system means that performance is difficult to predict fully.  Therefore, computational scientists are often forced to choose between investing too much time in tuning code or  accepting performance that is lower (and sometimes significantly lower) than peak.

Historically, the research community has pursued two separate paths toward the goal of making software run at near-peak levels.  The first of these builds on research into compilers and their associated technologies.  The holy grail of compilation research is to take an arbitrary code as input and produce optimal code as output for a given language and hardware platform.  Despite the immense effort that has been poured into this approach, its success has been limited both by practical constraints (users will not tolerate compile times that extend into several days) and by the amount of detailed information the compiler can obtain about the software to be compiled and the hardware on which it is to execute~\cite{Ken99,Wol89,Wol96}.

The second path has been to identify kernel routines that constitute the dominant costs of a wide variety of applications.  When such kernels can be identified and agreed upon by the members of the community, programmers with the required level of technical knowledge can concentrate on producing these optimized kernel libraries for architectures of interest. A prime example is the high-performance BLAS libraries produced by a combination of hardware vendors, independent software vendors, and researchers.  Developers who write their codes calling these routines can achieve high performance across all supported architectures. The efforts in high-performance library development aptly demonstrate, however, that the research into compiler technologies has not been fully successful.  If compilers could take the relatively simple code for basic tasks such as a dense matrix-matrix product and produce optimal code, this second approach would be unnecessary.

Like compiler optimization, the kernel library-oriented approach has significant limitations.  Support for a variety of architectures is the most serious problem because the optimizations necessary to achieve near-peak performance are by nature not portable.   This lack of portability is particularly problematic because processor designs are constantly changing,  and constant updates are nearly impossible to maintain by hand.  It is a sad fact of the computing industry that by the time highly-optimized code is available for a given architecture, that architecture is generally well on its way to obsolescence.

%This doesn't match our paper but I leave it here anyway.
We believe that addressing these barriers to performance optimization requires a paradigm shift from standard approaches, a shift that augments traditional techniques with an automated process that experimentally tests software on target architectures and modifies the code accordingly.


To begin, we are using matrix algebra operations.

\section{Background}
\label{sec:background}

To date, efforts toward automatically tuned software have focused largely on linear algebra.  These systems all have the same structure.  A collection of implementations is generated and timed, and the best choice is then identified.  One such early effort that combined automated code generation and empirical timings for automatic tuning was the PHiPAC (Portable High Performance Ansi C) \cite{lawn111} project.  PHiPAC generates parameterized code that can be tuned to machine specifications.  Basic optimizations in the code include manual loop unrolling, explicit removal of unnecessary dependencies in code blocks, and use of machine sympathetic C constructs. Search scripts are provided that, for a given code generator, find the best set of parameters for a given architecture and compiler. A follow-on to PHiPAC, the Sparsity system \cite{SPARSITY}, allows users to build sparse matrix kernels that are tuned to their matrices and machines automatically. Sparsity combines traditional techniques such as loop transformations with data structure transformations and optimization heuristics that are specific to sparse  matrices. It is based on a framework for selecting optimization parameters, such as block sizes, using a combination of performance models and search.

Should update to include OSKI.

ATLAS produces dense linear algebra kernels that have portable high efficiency across a variety of platforms. Like PHiPAC, ATLAS employs a test and search strategy. The automatic output of ATLAS is highly efficient implementations of the BLAS and of a limited set of LAPACK routines. Even in this narrow incarnation, ATLAS produces valuable results, since these subprograms are the essential computational building blocks of many scientific computing codes and of many general-purpose libraries such as LAPACK or PETSc~\cite{BGC+98}.  Moreover, ATLAS-based BLAS are immediately and directly reusable in software designed and written for distributed-memory concurrent computers, since optimized kernels are also heavily used locally by each processor in many scientific computing applications.

Another project that lies outside of the domain of linear algebra, is FFTW (Fastest FFT in the West)~\cite{frigo98, frigo99} for tuning discrete fast Fourier transforms.  FFTW uses the Cooley-Tukey algorithm and relies on explicit recursion in order to improve locality.   It also follows the test-and-search procedure of the linear algebra systems. FFTW creates sequences of instructions for the evaluation of the FFT called {\em plans}. Using a dynamic programming algorithm, it then efficiently searches through the plans to identify an optimal one.

\section{Composed Operations}
\label{sec:composed}

%These words swiped from the recent DOE proposal.  

To begin, we will focus on the matrix algebra that is a foundational part of many scientific applications. Codes based on matrix algebra are typically constructed as a sequence of calls to the Basic Linear Algebra Subprograms (BLAS)~\cite{Dongarra:1988uq,Lawson:1979kx,Dongarra:1990fk} and similar sparse matrix libraries~\cite{Saad:fr,George:1981uq}. Writing programs in this way promotes readability and maintainability but can be costly in terms of memory efficiency. While highly tuned implementations of the BLAS are available~\cite{Bilmes:1997ye,Whaley:1998fk,IntelMath:oq,ESSL:kl,Goto:2006fk}, the retrieval of a large order matrix at each routine call can have a profound effect on performance. Indeed, the PIs and other researchers have observed that a sequence of BLAS calls can be substantially less efficient than a call to a single specialized routine that performs the same operations (i.e, a {\it composed} BLAS routine)~\cite{Ashby:uq,Blackford:2002vn,Stanley:CSD-98-992,baker03blgmres,baker03lgmres,Dennis:2005tg,Howell:2008,gropp01,Vuduc:2003kl}. There are several ways to construct composed BLAS. As an example, consider the pair of matrix-vector products
$q  = Ap$, $s  = A^Tr$, where $A$ is a matrix and $p$, $q$, $r$, and $s$ are vectors, that comprise the computational
bottleneck of the BiConjugate Gradient Method~\cite{Barrett:1994kx,Saad:2003fk}.  These two operations can be implemented as a pair of calls to the BLAS routine {\tt GEMV} or they can be rewritten as a single doubly nested loop encompassing both matrix-vector multiplies. In the former case, the matrix $A$ is accessed twice while, in the latter, is it accessed only a single time. Our preliminary results indicate that this loop fusion leads to a routine that delivers 90\% more megaflops than does a pair of calls to the highly optimized Goto BLAS~\cite{Goto:2006fk} {\tt GEMV} routines for large matrix orders.

Composed routines are the focus of the work presented here, but much of what we discuss generalizes to a much broader array of computations.   Extending our approach will be the subject of future work.

% While large speedups are probable, composition can  also force memory accesses to be consecutive, and it can

%lead to the need to bring more data into cache. These bad

% effects can be remedied by combining composition with other tuning techniques like cache blocking and software pipelining. 


\section{Our Approach}
\label{sec:approach}

To generate highly optimized code from a MATLAB prototype, we will follow a three-step approach.    To begin, we will use a compiler that converts a MATLAB script into simple C code.  

Matlab compiler -> Pluto ->  Orio

\subsection{A Matlab Compiler}
\label{sec:matlab}

Figure~\ref{fig:compiler} gives an overview of the compilation process. The MATLAB kernel specification is parsed into a high-level intermediate representation in the form of a dataflow graph.  This dataflow graph is then iteratively processed until all of the implementation choices have been made.  The compilation process consists of three phases: analysis, lowering, and optimization, which are together iterated until all of the implementation decisions have been made.  The graph is then translated into C code.

\begin{figure}[htbp]
  \centering

  \caption{Overview of the Matlab compiler.}
\label{fig:compiler}
\end{figure}


\subsubsection{The Dataflow Graph}

An example dataflow graph for the GEMVER kernel, defined below, is given in figure~\ref{fig:gemver-dataflow}.
\begin{eqnarray*}
  A &\gets A + u_1 v_1^T + u_2 v_2^T \\[-0.5ex]
  x &\gets \beta A^T y + z \\[-0.5ex]
  w &\gets \alpha A x
\end{eqnarray*}
Each node represents a parameter of the kernel or an operation.  The arrows indicate the flow of data. At first the graph specifies what operations are to be performed but does not contain any implementation details. The symbol $\times$ in the depicted graph stands variously for outer product, matrix-vector multiplication, and scalar-vector multiplication, and it does not yet specify, for example, whether the outer products compute a row or a column at a time of the result matrix.

\begin{figure}[htbp]
  \centering
 
\caption{Dataflow graph for the GEMVER kernel.}
  \label{fig:gemver-dataflow}
\end{figure}

\subsubsection{Analyze the Dataflow Graph}

At the beginning of the analysis phase, each input and output node of the dataflow graph is labeled with its kind (scalar, vector, matrix, or unknown) and storage format (dense row-major, dense column-major, or unknown) according to the annotation given by the user.  During analysis, the kind and storage format are computed for the intermediate nodes and algorithms are assigned to operation nodes. The choice of algorithm and the determination of kinds of storage formats are interrelated so they must be computed together.  For example, the $\times$ symbol in the graph in Figure~\ref{fig:gemver-dataflow} having the inputs $u_1$ and $v_1^T$ can be implemented by iterating over rows first, or over columns first. The choice depends on how the result is used downstream in the dataflow graph.  In this case, the result is added to the outer product of $u_2$ and $v_2^T$, so we still could choose either option as long as we make the same choice for both outer products. Going one more step downstream, there is an addition with $A$, which was annotated in Figure~\ref{fig:gemver} to be column major. At this point it is clear that the outer-products should be computed in column-major order.

We do not hard code this knowledge of basic linear algebra in the compiler algorithm itself, but instead use a data-driven approach and store information regarding how to implement basic linear algebra in a separate database, which we refer to as the \emph{linear algebra database}.  This separation allows us to add new matrix formats, operations, and basic linear algebra algorithms without changes to the
compiler algorithm. 

The analysis algorithm makes implementation choices using the most-constrained first strategy (also called minimum remaining values)
from the artificial intelligence literature~\cite{Russell:2003mz}.This may need to be updated depending on how we decide to talk about the empirical search. -Jeremy 8/6/08 10:15 AM 
The compiler chooses the node with the fewest matching implementations (in the linear algebra database) and assigns a matching implementation to the node.  If there is more than one match, the prototype compiler picks the first.  Once we add backtracking we will push each alternative onto the stack to be explored later. Once the choice is made, the kind and storage format labels for the operation node itself and for the input nodes are updated with the labels specified in the linear algebra database for the chosen algorithm. The algorithm then goes on to find the next node with the fewest matching implementations and repeats.  In this phase, only the name of the algorithm is assigned to the operation node.  The details of the implementation are not specified until the refinement phase.


\subsection{Refine the Dataflow Graph}
\label{sec:refine}

The refinement phase resolves the implementation for each operation node in the graph into a subgraph defining the details of the chosen algorithm.  Each subgraph is an abstract representation of the loop that implements the given operation.  In each case, the subgraph has an iteration strategy that specifies how to traverse the elements of the matrix or vector.

Figure~\ref{fig:refine-mv-dot} shows two steps of refinement for a matrix-vector multiplication. The first step expands the matrix-vector multiplication according to the mv-dot algorithm from figure~\ref{fig:algos}.  The refinement step replaces the $\times$ node with a subgraph that computes the inner product of a row of the matrix---the node labeled $(i,:)$---with the vector, storing the result in the $i$th element of the result vector---the node labeled $(i)$. The subgraph is labeled with $i=1\!:\!m$ indicating that the iteration strategy is to traverse the rows of the dense matrix.
%
The second pass of refinement introduces another subgraph to implement the inner products (the dot algorithm from figure~\ref{fig:algos}). The new subgraph iterates through each dense row, as indicated by the $j=1:n$ annotation. The sign $\Sigma$ indicates that the sum of all of the iterations is computed.


\begin{figure*}[btp]
  \centering

  \caption{The refinement of a matrix-vector product to a set of inner products and the refinement of inner products to scalar multiplications and additions.}
  \label{fig:refine-mv-dot}
\end{figure*}




\subsubsection{Optimize the Dataflow Graph}

In the optimization step, the dataflow graph is optimized by applying conditional graph rewrite rules.  One example rewrite rule is \emph{Merge Operand Sharing Subgraphs}: if two subgraphs share a common operand but do not depend on one another, and if the iteration strategies of the two subgraphs are compatible, then merge the subgraphs into a single subgraph.  This rule is responsible for fusing the loops of the two matrix-vector products in the GEMVER kernel.  Another example rule is \emph{Merge Dependent Subgraphs}: if one subgraph depends on another subgraph, and the iteration strategies of the two subgraphs are compatible, then merge them into a single subgraph.  This rule, for example, is responsible for fusing the loops of the two outer products in the GEMVER kernel.

The choice of which optimizations to apply to various parts of the graph depends on the characteristics of the kernel, the algorithm, the matrix order and kind, and architectural features.  The following is an instructive example: $y \gets A^T A (x + z + w)$.  Assume that the compiler has already merged the two vector additions into one subgraph, call it $S_1$, and the two matrix products into another subgraph, call it $S_2$. The question then is whether it is profitable to apply the Merge Dependent Subgraphs rule one more time to merge $S_1$ and $S_2$. If the three vectors plus a row of $A$ do not fit in cache, then the merger will not be profitable because it will cause each row of $A$ to fall out of cache before the row gets used a second time.  On the other hand, if all three vectors plus a row of $A$ do it in cache, then $S_1$ and $S_2$ should be merged.  In general, we need a way to search through the many different combinations of optimization choices and choose a combination that minimizes memory traffic.

\subsubsection{Search Space Exploration and Evaluation}
\label{sec:search}

This will need updating depending on how we decide to address this topic. -Jeremy 8/6/08 10:19 AM 
The set of all possible combinations of implementation and optimization choices is called the search space~\cite{Kisuki:2000uq,Triantafyllis:2003uq, Cooper:2005kx}.  Although the dataflow graphs are quite small in our setting (usually less than 100 nodes), it is still important to prune the search space to avoid an exponential compilation time. Our prototype already performs some pruning: the optimization rewrite rules only apply under certain circumstances.  However, as mentioned above we are sometimes overly aggressive in applying optimizations. To solve this problem we plan to use a combination of analytic methods and empirical
methods~\cite{Chen:2007vn}.
%Yotov:2005kx
We plan to use a fast analytic cost function to prune out regions of the search space that will not produce competitive implementations. The cost function is based on a model of the computer architecture, but does not necessarily account for all the details.  Once the search space is narrowed, we will use empirical testing with representative data sets to determine the exact performance of the alternatives and choose the best one.

\subsubsection{Translate the Dataflow Graph to C}

A graph that cannot be further refined has been reduced to a collection of subgraphs representing loops over scalar operations. The generator outputs a C loop for each subgraph.  The order in which the loops, and scalar operations within the loops, appear in the output is determined by performing a topological sort.





\subsection{PLuTo}
\label{sec:plutonorio}
% http://www.cse.ohio-state.edu/~bondhugu/pluto/

PLuTo~\cite{uday07tr70,uday08cc} is a source-to-source transformation tool for optimizing sequences of (possibly nested) loops.

\subsection{Orio}
\label{sec:orio}

Orio~\cite{Norris:2007} is an empirical tuning tool that takes as input annotated C code and generates multiple tuned versions of the annotated code. Orio does not parse the application code; rather, it relies on annotations expressed as structured comments, which contain a simplified expression of the computation, as well as directives on what transformations to apply.

% TODO (Boyana): redo this figure

\subsection{Putting it All Together}
\label{sec:combining}

\section{Experimental Results}
\label{sec:experiments}

\section{Multicore?}
\label{sec:multicore}

\section{Conclusions}

\bibliography{paper}
\bibliographystyle{siam}


\end{document}

